{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71e154df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matching files: 44\n",
      "Files with 'post_chat': 41\n",
      "\n",
      "Files containing 'post_chat' in condition column:\n",
      "  - FINS_004c_aligned_timeseries_filtered.csv\n",
      "  - FINS_006c_aligned_timeseries_filtered.csv\n",
      "  - FINS_007c_aligned_timeseries_filtered.csv\n",
      "  - FINS_008c_aligned_timeseries_filtered.csv\n",
      "  - FINS_009c_aligned_timeseries_filtered.csv\n",
      "  - FINS_010c_aligned_timeseries_filtered.csv\n",
      "  - FINS_011c_aligned_timeseries_filtered.csv\n",
      "  - FINS_013c_aligned_timeseries_filtered.csv\n",
      "  - FINS_014c_aligned_timeseries_filtered.csv\n",
      "  - FINS_015c_aligned_timeseries_filtered.csv\n",
      "  - FINS_016c_aligned_timeseries_filtered.csv\n",
      "  - FINS_017c_aligned_timeseries_filtered.csv\n",
      "  - FINS_018c_aligned_timeseries_filtered.csv\n",
      "  - FINS_019c_aligned_timeseries_filtered.csv\n",
      "  - FINS_021c_aligned_timeseries_filtered.csv\n",
      "  - FINS_022c_aligned_timeseries_filtered.csv\n",
      "  - FINS_023c_aligned_timeseries_filtered.csv\n",
      "  - FINS_024c_aligned_timeseries_filtered.csv\n",
      "  - FINS_025c_aligned_timeseries_filtered.csv\n",
      "  - FINS_027c_aligned_timeseries_filtered.csv\n",
      "  - FINS_029c_aligned_timeseries_filtered.csv\n",
      "  - FINS_032c_aligned_timeseries_filtered.csv\n",
      "  - FINS_033c_aligned_timeseries_filtered.csv\n",
      "  - FINS_036c_aligned_timeseries_filtered.csv\n",
      "  - FINS_037c_aligned_timeseries_filtered.csv\n",
      "  - FINS_038c_aligned_timeseries_filtered.csv\n",
      "  - FINS_039c_aligned_timeseries_filtered.csv\n",
      "  - FINS_040c_aligned_timeseries_filtered.csv\n",
      "  - FINS_043c_aligned_timeseries_filtered.csv\n",
      "  - FINS_044c_aligned_timeseries_filtered.csv\n",
      "  - FINS_045c_aligned_timeseries_filtered.csv\n",
      "  - FINS_048c_aligned_timeseries_filtered.csv\n",
      "  - FINS_049c_aligned_timeseries_filtered.csv\n",
      "  - FINS_050c_aligned_timeseries_filtered.csv\n",
      "  - FINS_051c_aligned_timeseries_filtered.csv\n",
      "  - FINS_052c_aligned_timeseries_filtered.csv\n",
      "  - FINS_053c_aligned_timeseries_filtered.csv\n",
      "  - FINS_054c_aligned_timeseries_filtered.csv\n",
      "  - FINS_055c_aligned_timeseries_filtered.csv\n",
      "  - FINS_056c_aligned_timeseries_filtered.csv\n",
      "  - FINS_057c_aligned_timeseries_filtered.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the directory path\n",
    "data_dir = Path(\"../aligned_timeseries_FINS\")\n",
    "\n",
    "# Get all CSV files matching the pattern\n",
    "matching_files = [f for f in data_dir.glob(\"FINS_*c_*_filtered.csv\")]\n",
    "\n",
    "# List to store files with post_chat\n",
    "files_with_post_chat = []\n",
    "\n",
    "# Check each file for post_chat in condition column\n",
    "for file_path in matching_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        if 'condition' in df.columns:\n",
    "            if 'post_chat' in df['condition'].values:\n",
    "                files_with_post_chat.append(file_path.name)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path.name}: {e}\")\n",
    "\n",
    "# Print results\n",
    "print(f\"Total matching files: {len(matching_files)}\")\n",
    "print(f\"Files with 'post_chat': {len(files_with_post_chat)}\")\n",
    "print(\"\\nFiles containing 'post_chat' in condition column:\")\n",
    "for filename in sorted(files_with_post_chat):\n",
    "    print(f\"  - {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6b10fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv('../aligned_timeseries_FINS/FINS_056c_aligned_timeseries_filtered.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5130ccf",
   "metadata": {},
   "source": [
    "## Plan for fitting two independent HMMs (child1 HMM, child2 HMM), then compare state sequences\n",
    "\n",
    "### Step 1 — Load both CSVs\n",
    "\n",
    "### Step 2 — Filter to `post_chat`\n",
    "\n",
    "### Step 3 — Select HbO columns only → build X\n",
    "\n",
    "### Step 4 — EDA on filtered data\n",
    "\n",
    "* duration (sec/min)\n",
    "* sampling rate (~10 Hz)\n",
    "* missingness rate (fraction of NaNs)\n",
    "* number of HbO channels\n",
    "\n",
    "### Step 5 — Standardize X (mean 0, std 1 per HbO channel)\n",
    "\n",
    "### Step 6 — Fit HMM on each file (same K)\n",
    "\n",
    "* start with K = 4..10\n",
    "* pick K later by BIC/stability; for now pick a reasonable K like 6\n",
    "\n",
    "### Step 7 — Align state labels across the two HMMs (Hungarian)\n",
    "\n",
    "* align by similarity of state mean patterns\n",
    "\n",
    "### Step 8 — Compare aligned outputs\n",
    "\n",
    "* fractional occupancy per aligned state\n",
    "* dwell time per aligned state\n",
    "\n",
    "Focused on:\n",
    "\n",
    "* `condition == \"post_chat\"`\n",
    "* **HbO only**\n",
    "* EDA: minutes, sampling rate, missingness\n",
    "* standardization (recommended for HMM stability)\n",
    "* fit HMM to each file\n",
    "* align states between the two HMMs using **Hungarian algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd2abe1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip -q install hmmlearn scikit-learn scipy pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76d05777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b40b92",
   "metadata": {},
   "source": [
    "### EDA Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2df56adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hbo_columns(df):\n",
    "    # Matches columns ending with ' hbo' (case-insensitive)\n",
    "    return [c for c in df.columns if c.lower().endswith(\" hbo\")]\n",
    "\n",
    "def missingness_rate(X):\n",
    "    # fraction of NaNs in the whole matrix\n",
    "    return float(np.isnan(X).mean())\n",
    "\n",
    "def eda_postchat_hbo(df, name=\"file\"):\n",
    "    \"\"\"\n",
    "    Filter to post_chat condition, extract HbO columns, and report EDA stats.\n",
    "    Assumes 10 Hz sampling rate.\n",
    "    \"\"\"\n",
    "    if \"condition\" not in df.columns:\n",
    "        raise ValueError(f\"{name}: no 'condition' column found.\")\n",
    "    \n",
    "    # Show available conditions for debugging\n",
    "    print(f\"\\nAvailable conditions in {name}: {list(pd.unique(df['condition']))}\")\n",
    "    \n",
    "    # Filter to post_chat\n",
    "    d = df[df[\"condition\"] == \"post_chat\"].copy()\n",
    "    \n",
    "    if len(d) == 0:\n",
    "        raise ValueError(f\"{name}: no rows found with condition == 'post_chat'.\")\n",
    "    \n",
    "    # Get HbO columns\n",
    "    hbo_cols = get_hbo_columns(d)\n",
    "    if len(hbo_cols) == 0:\n",
    "        raise ValueError(f\"{name}: no HbO columns found after filtering to post_chat.\")\n",
    "    \n",
    "    # Extract data\n",
    "    X = d[hbo_cols].astype(float).values\n",
    "    \n",
    "    # Calculate duration from row count (10 Hz sampling)\n",
    "    sampling_hz = 10.0\n",
    "    duration_sec = len(d) / sampling_hz\n",
    "    duration_min = duration_sec / 60.0\n",
    "    \n",
    "    # Calculate missingness\n",
    "    miss = missingness_rate(X)\n",
    "    \n",
    "    # Print EDA summary\n",
    "    print(f\"\\n=== EDA (post_chat, HbO only): {name} ===\")\n",
    "    print(f\"Total rows in file: {len(df)}\")\n",
    "    print(f\"Post_chat rows: {len(d)}\")\n",
    "    print(f\"Percentage: {100 * len(d) / len(df):.1f}%\")\n",
    "    print(f\"HbO channels (D): {len(hbo_cols)}\")\n",
    "    print(f\"Duration: {duration_sec:.2f} sec (~{duration_min:.2f} min)\")\n",
    "    print(f\"Missingness rate (NaN fraction): {miss:.6f}\")\n",
    "    \n",
    "    # Return time column for compatibility (though not used downstream)\n",
    "    t = d[\"time_sec\"].values if \"time_sec\" in d.columns else np.arange(len(d)) / sampling_hz\n",
    "    \n",
    "    return d, hbo_cols, X, t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc9cf2e",
   "metadata": {},
   "source": [
    "### Loading files + run post_chat HbO EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bbbb7b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available conditions in FINS_056c: ['pre_chat', 'easy_talking', 'easy_silence', 'med_talking', 'med_silence', 'hard_talking', 'hard_silence', 'post_chat']\n",
      "\n",
      "=== EDA (post_chat, HbO only): FINS_056c ===\n",
      "Total rows in file: 5679\n",
      "Post_chat rows: 799\n",
      "Percentage: 14.1%\n",
      "HbO channels (D): 22\n",
      "Duration: 79.90 sec (~1.33 min)\n",
      "Missingness rate (NaN fraction): 0.000000\n",
      "\n",
      "Available conditions in FINS_057c: ['pre_chat', 'easy_talking', 'easy_silence', 'med_talking', 'med_silence', 'hard_talking', 'hard_silence', 'post_chat']\n",
      "\n",
      "=== EDA (post_chat, HbO only): FINS_057c ===\n",
      "Total rows in file: 5699\n",
      "Post_chat rows: 688\n",
      "Percentage: 12.1%\n",
      "HbO channels (D): 22\n",
      "Duration: 68.80 sec (~1.15 min)\n",
      "Missingness rate (NaN fraction): 0.000000\n",
      "\n",
      "Common HbO channels: 22\n"
     ]
    }
   ],
   "source": [
    "file_a = f\"{data_dir}/FINS_056c_aligned_timeseries_filtered.csv\"\n",
    "file_b = f\"{data_dir}/FINS_057c_aligned_timeseries_filtered.csv\"\n",
    "\n",
    "df_a = pd.read_csv(file_a)\n",
    "df_b = pd.read_csv(file_b)\n",
    "\n",
    "d_a, hbo_a, Xa, ta = eda_postchat_hbo(df_a, name=\"FINS_056c\")\n",
    "d_b, hbo_b, Xb, tb = eda_postchat_hbo(df_b, name=\"FINS_057c\")\n",
    "\n",
    "# Ensure we use the same HbO channels in both (intersection if needed)\n",
    "common_hbo = sorted(list(set(hbo_a).intersection(set(hbo_b))))\n",
    "print(\"\\nCommon HbO channels:\", len(common_hbo))\n",
    "\n",
    "Xa = d_a[common_hbo].astype(float).values\n",
    "Xb = d_b[common_hbo].astype(float).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809550c4",
   "metadata": {},
   "source": [
    "### Standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cfe968cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(X):\n",
    "    scaler = StandardScaler()\n",
    "    Xz = scaler.fit_transform(X)\n",
    "    return Xz, scaler\n",
    "\n",
    "Xa_z, scaler_a = standardize(Xa)\n",
    "Xb_z, scaler_b = standardize(Xb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29247ef8",
   "metadata": {},
   "source": [
    "### Fit HMM (no PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f02db12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_hmm(Xz, K, seed=0, n_iter=500):\n",
    "    model = GaussianHMM(\n",
    "        n_components=K,\n",
    "        covariance_type=\"diag\",\n",
    "        n_iter=n_iter,\n",
    "        tol=1e-3,\n",
    "        random_state=seed\n",
    "    )\n",
    "    model.fit(Xz)\n",
    "    z = model.predict(Xz)\n",
    "    return model, z\n",
    "\n",
    "K = 6  # starter value; we can sweep K later\n",
    "\n",
    "model_a, z_a = fit_hmm(Xa_z, K=K, seed=0)\n",
    "model_b, z_b = fit_hmm(Xb_z, K=K, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bc0495",
   "metadata": {},
   "source": [
    "### Hungarian alignment (align B’s states to A’s labels)\n",
    "We align using cosine similarity of the state mean vectors (`model.means_`), which are in the standardized feature space here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e131b3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping (A_state -> B_state): [4, 5, 3, 2, 1, 0]\n",
      "Avg matched similarity: 0.27999338086159187\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity_matrix(A, B, eps=1e-9):\n",
    "    A_norm = A / (np.linalg.norm(A, axis=1, keepdims=True) + eps)\n",
    "    B_norm = B / (np.linalg.norm(B, axis=1, keepdims=True) + eps)\n",
    "    return A_norm @ B_norm.T\n",
    "\n",
    "def hungarian_align(means_a, means_b):\n",
    "    S = cosine_similarity_matrix(means_a, means_b)\n",
    "    cost = -S  # maximize similarity\n",
    "    row_ind, col_ind = linear_sum_assignment(cost)\n",
    "    # col_ind[a_state] = matched b_state\n",
    "    return col_ind, S\n",
    "\n",
    "def remap_states_b_to_a(z_b, mapping_a_to_b):\n",
    "    # Build inverse map: inv[b_state] = a_state\n",
    "    inv = np.zeros_like(mapping_a_to_b)\n",
    "    for a_state, b_state in enumerate(mapping_a_to_b):\n",
    "        inv[b_state] = a_state\n",
    "    return inv[z_b]\n",
    "\n",
    "mapping_a_to_b, sim = hungarian_align(model_a.means_, model_b.means_)\n",
    "z_b_aligned = remap_states_b_to_a(z_b, mapping_a_to_b)\n",
    "\n",
    "print(\"Mapping (A_state -> B_state):\", mapping_a_to_b.tolist())\n",
    "print(\"Avg matched similarity:\", float(np.mean([sim[a, mapping_a_to_b[a]] for a in range(K)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2fb228",
   "metadata": {},
   "source": [
    "### Compare aligned occupancy + dwell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a1b47aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FO A: [0.218 0.242 0.081 0.091 0.215 0.153]\n",
      "FO B (aligned): [0.113 0.215 0.126 0.188 0.166 0.192]\n",
      "Mean dwell A (steps): [ 87.   96.5  32.5  24.3  57.3 122. ]\n",
      "Mean dwell B (aligned, steps): [ 26.  148.   87.   21.5  28.5  22. ]\n"
     ]
    }
   ],
   "source": [
    "def fractional_occupancy(z, K):\n",
    "    return np.bincount(z, minlength=K) / len(z)\n",
    "\n",
    "def mean_dwell(z, K):\n",
    "    dw = {k: [] for k in range(K)}\n",
    "    s, run = z[0], 1\n",
    "    for i in range(1, len(z)):\n",
    "        if z[i] == s:\n",
    "            run += 1\n",
    "        else:\n",
    "            dw[s].append(run)\n",
    "            s, run = z[i], 1\n",
    "    dw[s].append(run)\n",
    "    return np.array([np.mean(dw[k]) if dw[k] else 0.0 for k in range(K)])\n",
    "\n",
    "fo_a = fractional_occupancy(z_a, K)\n",
    "fo_b = fractional_occupancy(z_b_aligned, K)\n",
    "\n",
    "dt_a = mean_dwell(z_a, K)\n",
    "dt_b = mean_dwell(z_b_aligned, K)\n",
    "\n",
    "print(\"\\nFO A:\", np.round(fo_a, 3))\n",
    "print(\"FO B (aligned):\", np.round(fo_b, 3))\n",
    "print(\"Mean dwell A (steps):\", np.round(dt_a, 1))\n",
    "print(\"Mean dwell B (aligned, steps):\", np.round(dt_b, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae9b155",
   "metadata": {},
   "source": [
    "# Debug and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3291fa15",
   "metadata": {},
   "source": [
    "### DEBUG PER FILE post_chat Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1fde8d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pre_chat' 'easy_talking' 'easy_silence' 'med_talking' 'med_silence'\n",
      " 'hard_talking' 'hard_silence' 'post_chat']\n"
     ]
    }
   ],
   "source": [
    "file_a = f\"{data_dir}/FINS_040c_aligned_timeseries_filtered.csv\"\n",
    "# # file_a = f\"{data_dir}/FINS_056c_aligned_timeseries_filtered.csv\"\n",
    "# # file_b = f\"{data_dir}/FINS_057c_aligned_timeseries_filtered.csv\"\n",
    "\n",
    "df_a = pd.read_csv(file_a)\n",
    "print(pd.unique(df_a['condition']))\n",
    "\n",
    "# def eda_postchat_hbo(df, name=\"file\"):\n",
    "#     if \"condition\" not in df.columns:\n",
    "#         raise ValueError(f\"{name}: no 'condition' column found.\")\n",
    "#     if \"time_sec_rel\" not in df.columns:\n",
    "#         raise ValueError(f\"{name}: no 'time_sec_rel' column found.\")\n",
    "    \n",
    "#     print(pd.unique(df['condition']))\n",
    "\n",
    "#     d = df[df[\"condition\"] == \"post_chat\"].copy()\n",
    "#     # d.to_csv('post_chat_only.csv')\n",
    "#     print(\"all cols + post chat values\", d.shape)\n",
    "#     hbo_cols = get_hbo_columns(d)\n",
    "#     if len(hbo_cols) == 0:\n",
    "#         raise ValueError(f\"{name}: no HbO columns found after filtering to post_chat.\")\n",
    "    \n",
    "#     X = d[hbo_cols].astype(float).values\n",
    "#     print(X.shape)\n",
    "    \n",
    "#     duration_sec = len(d)/10.0\n",
    "#     duration_min = duration_sec / 60.0\n",
    "#     # med_dt, hz = estimate_sampling_rate(t)\n",
    "#     miss = missingness_rate(X)\n",
    "    \n",
    "#     print(f\"\\n=== EDA (post_chat, HbO only): {name} ===\")\n",
    "#     print(\"Rows (time points):\", len(d))\n",
    "#     print(\"HbO channels (D):\", len(hbo_cols))\n",
    "#     print(f\"Duration: {duration_sec:.2f} sec (~{duration_min:.2f} min)\")\n",
    "#     # print(f\"Estimated sampling: dt≈{med_dt:.4f}s  ->  {hz:.2f} Hz\")\n",
    "#     print(f\"Missingness rate (NaN fraction): {miss:.6f}\")\n",
    "\n",
    "#     print(f\"Total rows in file: {len(df_a)}\")\n",
    "#     print(f\"Post_chat rows: {len(d)}\")\n",
    "#     print(f\"Percentage: {100 * len(d) / len(df_a):.1f}%\")\n",
    "    \n",
    "#     return d, hbo_cols, X, d['time_sec']\n",
    "\n",
    "# a,b,c,d = eda_postchat_hbo(df_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2856ed",
   "metadata": {},
   "source": [
    "### Verifying matching dyad existance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c325e216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total child files: 44\n",
      "Total parent files: 44\n",
      "Matched dyads (have both child & parent): 44\n",
      "\n",
      "Child files with 'post_chat': 41\n",
      "Parent files with 'post_chat': 41\n",
      "Complete pairs with 'post_chat' in both: 41\n",
      "\n",
      "=== Matched pairs with post_chat ===\n",
      "\n",
      "Dyad 004 (dyad_id: 4, match: True)\n",
      "  Child:  FINS_004c_aligned_timeseries_filtered.csv\n",
      "  Parent: FINS_004p_aligned_timeseries_filtered.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the directory path\n",
    "data_dir = Path(\"../aligned_timeseries_FINS\")\n",
    "\n",
    "# Get all CSV files matching child and parent patterns\n",
    "child_files = sorted(data_dir.glob(\"FINS_*c_*_filtered.csv\"))\n",
    "parent_files = sorted(data_dir.glob(\"FINS_*p_*_filtered.csv\"))\n",
    "\n",
    "# Create dictionaries to store dyad information\n",
    "child_dyads = {}  # {dyad_number: filename}\n",
    "parent_dyads = {}  # {dyad_number: filename}\n",
    "\n",
    "# Extract dyad numbers from filenames\n",
    "for file_path in child_files:\n",
    "    # Extract dyad number (e.g., \"040\" from \"FINS_040c_aligned_timeseries_filtered.csv\")\n",
    "    dyad_num = file_path.stem.split('_')[1].replace('c', '')\n",
    "    child_dyads[dyad_num] = file_path.name\n",
    "\n",
    "for file_path in parent_files:\n",
    "    # Extract dyad number (e.g., \"040\" from \"FINS_040p_aligned_timeseries_filtered.csv\")\n",
    "    dyad_num = file_path.stem.split('_')[1].replace('p', '')\n",
    "    parent_dyads[dyad_num] = file_path.name\n",
    "\n",
    "# Find dyads that have both child and parent files\n",
    "matched_dyads = set(child_dyads.keys()).intersection(set(parent_dyads.keys()))\n",
    "# print(sorted(matched_dyads))\n",
    "\n",
    "# Lists to store files with post_chat (for matched dyads only)\n",
    "child_files_with_post_chat = []\n",
    "parent_files_with_post_chat = []\n",
    "matched_pairs = []\n",
    "\n",
    "# Check matched dyads for post_chat condition\n",
    "for dyad_num in sorted(matched_dyads):\n",
    "    child_file = data_dir / child_dyads[dyad_num]\n",
    "    parent_file = data_dir / parent_dyads[dyad_num]\n",
    "    \n",
    "    child_has_post_chat = False\n",
    "    parent_has_post_chat = False\n",
    "    child_dyad_id = None\n",
    "    parent_dyad_id = None\n",
    "    \n",
    "    try:\n",
    "        # Check child file\n",
    "        df_child = pd.read_csv(child_file)\n",
    "        if 'condition' in df_child.columns and 'post_chat' in df_child['condition'].values:\n",
    "            child_has_post_chat = True\n",
    "            child_files_with_post_chat.append(child_dyads[dyad_num])\n",
    "            if 'dyad_id' in df_child.columns:\n",
    "                child_dyad_id = df_child['dyad_id'].iloc[0]\n",
    "        \n",
    "        # Check parent file\n",
    "        df_parent = pd.read_csv(parent_file)\n",
    "        if 'condition' in df_parent.columns and 'post_chat' in df_parent['condition'].values:\n",
    "            parent_has_post_chat = True\n",
    "            parent_files_with_post_chat.append(parent_dyads[dyad_num])\n",
    "            if 'dyad_id' in df_parent.columns:\n",
    "                parent_dyad_id = df_parent['dyad_id'].iloc[0]\n",
    "        \n",
    "        # Verify dyad_id matches\n",
    "        dyad_id_match = (child_dyad_id == parent_dyad_id) if (child_dyad_id and parent_dyad_id) else \"N/A\"\n",
    "        \n",
    "        # If both have post_chat, add to matched pairs\n",
    "        if child_has_post_chat and parent_has_post_chat:\n",
    "            matched_pairs.append({\n",
    "                'dyad_num': dyad_num,\n",
    "                'child_file': child_dyads[dyad_num],\n",
    "                'parent_file': parent_dyads[dyad_num],\n",
    "                'dyad_id_match': dyad_id_match,\n",
    "                'dyad_id': child_dyad_id if child_dyad_id else parent_dyad_id\n",
    "            })\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading dyad {dyad_num}: {e}\")\n",
    "\n",
    "# Print results\n",
    "print(f\"Total child files: {len(child_files)}\")\n",
    "print(f\"Total parent files: {len(parent_files)}\")\n",
    "print(f\"Matched dyads (have both child & parent): {len(matched_dyads)}\")\n",
    "print(f\"\\nChild files with 'post_chat': {len(child_files_with_post_chat)}\")\n",
    "print(f\"Parent files with 'post_chat': {len(parent_files_with_post_chat)}\")\n",
    "print(f\"Complete pairs with 'post_chat' in both: {len(matched_pairs)}\")\n",
    "\n",
    "print(\"\\n=== Matched pairs with post_chat ===\")\n",
    "for pair in matched_pairs:\n",
    "    print(f\"\\nDyad {pair['dyad_num']} (dyad_id: {pair['dyad_id']}, match: {pair['dyad_id_match']})\")\n",
    "    print(f\"  Child:  {pair['child_file']}\")\n",
    "    print(f\"  Parent: {pair['parent_file']}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c34f4e",
   "metadata": {},
   "source": [
    "### Finding condition lenghts for each child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee360630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "022c: 79.7 secs 797 rows\n",
      "053c: 76.8 secs 768 rows\n",
      "015c: 74.0 secs 740 rows\n",
      "011c: 122.0 secs 1220 rows\n",
      "057c: 68.8 secs 688 rows\n",
      "039c: 72.6 secs 726 rows\n",
      "048c: 61.0 secs 610 rows\n",
      "019c: 122.0 secs 1220 rows\n",
      "006c: 71.8 secs 718 rows\n",
      "040c: 61.0 secs 610 rows\n",
      "044c: 65.4 secs 654 rows\n",
      "043c: 61.0 secs 610 rows\n",
      "032c: 80.7 secs 807 rows\n",
      "029c: 11.1 secs 111 rows\n",
      "036c: 78.7 secs 787 rows\n",
      "021c: 61.0 secs 610 rows\n",
      "016c: 61.0 secs 610 rows\n",
      "050c: 66.6 secs 666 rows\n",
      "009c: 94.7 secs 947 rows\n",
      "025c: 80.1 secs 801 rows\n",
      "054c: 68.3 secs 683 rows\n",
      "045c: 67.0 secs 670 rows\n",
      "018c: 61.0 secs 610 rows\n",
      "007c: 73.6 secs 736 rows\n",
      "056c: 79.9 secs 799 rows\n",
      "010c: 61.0 secs 610 rows\n",
      "027c: 72.7 secs 727 rows\n",
      "049c: 69.4 secs 694 rows\n",
      "038c: 75.8 secs 758 rows\n",
      "014c: 122.0 secs 1220 rows\n",
      "052c: 32.8 secs 328 rows\n",
      "023c: 73.6 secs 736 rows\n",
      "013c: 122.0 secs 1220 rows\n",
      "055c: 70.3 secs 703 rows\n",
      "024c: 69.4 secs 694 rows\n",
      "051c: 65.9 secs 659 rows\n",
      "017c: 71.2 secs 712 rows\n",
      "008c: 122.0 secs 1220 rows\n",
      "037c: 72.8 secs 728 rows\n",
      "033c: 84.2 secs 842 rows\n",
      "004c: 67.1 secs 671 rows\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path(\"../aligned_timeseries_FINS\")\n",
    "\n",
    "# Get all CSV files matching the pattern\n",
    "matching_files = [f for f in data_dir.glob(\"FINS_*c_*_filtered.csv\")]\n",
    "\n",
    "# List to store files with post_chat\n",
    "files_with_post_chat = []\n",
    "\n",
    "# Check each file for post_chat in condition column\n",
    "for file_path in matching_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        if 'condition' in df.columns:\n",
    "            if 'post_chat' in df['condition'].values:\n",
    "                pc_df = df[df['condition'] == 'post_chat']\n",
    "                duration = len(pc_df)/10.0\n",
    "                print(f\"{file_path.name.split('_')[1]}: {duration} secs {len(pc_df)} rows\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path.name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2aa927a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4295\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['pre_chat', 'easy_talking', 'easy_silence', 'med_talking',\n",
       "       'med_silence', 'hard_talking', 'hard_silence', 'post_chat'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/ineshtandon/Documents/GitHub/REN_fNIRS_State_Analysis/aligned_timeseries_FINS/FINS_029c_aligned_timeseries_filtered.csv')\n",
    "print(len(df))\n",
    "pd.unique(df['condition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0e4c46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_mode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
